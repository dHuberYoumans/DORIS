{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with importing all necessary libraries, setting the current working directory and defining the relevant physical constant such as the _mass of the earth_ $M_{earth}$, Newton's _gravitational constant_ $G$ and the _standard gravitational parameter_ $\\mu \\approx G \\cdot M_{earth}$ (wher in the approximation we omit the mass of the satellite since $M_{earth} + M_{sat}\\approx M_{earth}$) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports complete\n"
     ]
    }
   ],
   "source": [
    "# PROCESSING DATA IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import scipy.constants\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# SYSTEM \n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# SPECIFY WORKING DIRECTORY (LOCATION OF SATELLITE .csv FILES)\n",
    "cwd = Path(os.getcwd())\n",
    "\n",
    "# VISUALISATION\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# IMPORT UTILITY FUNCIONS\n",
    "sys.path.append(str(cwd.parent)+'/src/') # append path to ./src/ for following imports\n",
    "import kepler_utils as kutls\n",
    "import ana_utils as autls\n",
    "import preprocessing_utils as preputls\n",
    "\n",
    "# ML IMPORTS\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import statsmodels.tsa.stattools as sts\n",
    "import statsmodels.graphics.tsaplots as sgt\n",
    "\n",
    "import pmdarima as pm\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "\n",
    "# CONSTANTS \n",
    "M_earth = 5.972E24 # earth mass [kg]\n",
    "G = scipy.constants.G # grav constant [m^3 s^{-2} kg^{-1}]\n",
    "mu = G*M_earth # standard grav parameter for m (mass moving object) << M_earth [m^3 s^{-2}]  \n",
    "\n",
    "print('imports complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script _download_DORIS_data.py_ downloads the data for a chosen satellite in a chosen time frame and for chosen control centers (which have computed the state vector from the raw observational data) and returns a single .csv-file. \n",
    "\n",
    "After the .csv-file is loaded, it contains duplicated time indices because the data is seperated into several .Z-files (to make downloads feasible) with overlapping starting and ending times of the observations. These indices have to be dropped.\n",
    "\n",
    "Moreover, the original data is provided in a _SP3 format_ which records positions in **km** and velocities in **dm/s**. \n",
    "To be conform with the phyisical constant we have defined, we convert these units into **m** and **m/s**.\n",
    "\n",
    "For the sake of readibility of the code, we create a single pipeline to load and preprocess the data (as above) using `sklearn.pipeline.Pipeline` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " loading of satellite data complete.\n"
     ]
    }
   ],
   "source": [
    "sat_path = str(cwd.parent)+'/sat/s6assa2024/s6assa_20_24.csv'\n",
    "\n",
    "if not os.path.isfile(sat_path):\n",
    "    raise Exception('Indicated path does not point to a valid file')\n",
    "\n",
    "# DEFINE CUSTOM TRANSFORMERS\n",
    "load_sat = preputls.LoadSingleSat(path=sat_path)\n",
    "drop_dupl_idx = preputls.DropDuplIdx()\n",
    "convert_units = preputls.ConvertUnits()\n",
    "\n",
    "# BUILD PIPELINE FOR PREPROCESSING\n",
    "prep_pipeline = Pipeline(\n",
    "    steps=[\n",
    "    ('load_sat', load_sat),                 # load satellite data\n",
    "    ('drop_duplicated_idx', drop_dupl_idx), # drop duplicated indices\n",
    "    ('convert_units',convert_units)         # convert units \n",
    "])\n",
    "\n",
    "# LOAD AND PREPROCESS SATELLITE DATA \n",
    "s6ssa = prep_pipeline.fit_transform(None)\n",
    "\n",
    "print('\\n loading of satellite data complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the scheduled manoeuvres obtained from the _download_maneuver_schedule.py_ script and filter the data for the manoeuvres scheduled for _Sentinel 6a_ between 01/01/2020 and 12/31/2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading manoeuvres complete\n"
     ]
    }
   ],
   "source": [
    "# LOADING LIST OF PRE-SCHEDULED MANEUVERS\n",
    "path_ref = str(cwd.parent)+'/ref/'\n",
    "\n",
    "if os.path.isdir(path_ref):\n",
    "    path_list_man = path_ref + '/manoeuvres_schedule.csv'\n",
    "    if os.path.isfile(path_list_man):\n",
    "           manoeuvres = pd.read_csv(path_list_man,index_col=0)\n",
    "    else: \n",
    "        raise Exception(f'No file named maneuvers_schedule.csv found.')\n",
    "else:\n",
    "    raise Exception(f'No directory named {path_ref} found.')\n",
    "   \n",
    "manoeuvres.start = pd.to_datetime(manoeuvres.start)\n",
    "manoeuvres.end = pd.to_datetime(manoeuvres.end)\n",
    "\n",
    "mans6a2024 = manoeuvres[(manoeuvres.sat_id == 's6a') & (manoeuvres.start.dt.year.isin(range(2020,2025)))].drop(['sat_id','end'],axis=1).set_index('start').sort_index()\n",
    "\n",
    "print('loading manoeuvres complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DORIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
